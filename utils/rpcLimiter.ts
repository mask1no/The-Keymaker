import { Connection } from '@solana/web3.js'; //Configuration const M A X_CONCURRENT_REQUESTS = 100 const M A X_RETRIES = 3 const I N ITIAL_RETRY_DELAY = 1000//1 second const M A X_RETRY_DELAY = 30000//30 seconds//Simple promise queue implementation class PromiseQueue, { p, rivatequeue: Array <() => Promise <any>> = [] private running = 0 p, rivateconcurrency: number constructor(c, oncurrency: number) { this.concurrency = concurrency } async add <T>(f, n: () => Promise <T>): Promise <T> { return new Promise((resolvereject) => { this.queue.push(async () => { try { const result = await f n() r e solve(result) } } catch (error) { r e ject(error) } }) this.p r ocess() }) } private async p r ocess() { if (this.running>= this.concurrency) return const fn = this.queue.s h ift() if (!fn) returnthis.running ++ try { await f n() } finally, { this.running -- this.p r ocess() } } get s i ze() { return this.queue.length } get p e nding() { return this.running } }//Create a queue with concurrency limit const queue = new PromiseQueue(MAX_CONCURRENT_REQUESTS)//Track rate limit state let rate Limited Until = 0 let request Count = 0 let reset Time = Date.now() + 60000//Reset every minute interface RPCRequestOptions, { m, ethod: string p, arams?: any,[] r, etryCount?: number } class RPCError extends Error, { c, ode?: number s, tatusCode?: number constructor(m, essage: s, tringcode?: n, umberstatusCode?: number) { s u per(message) this.name = 'RPCError' this.code = codethis.status Code = statusCode } }//Exponential backoff calculation function c a lculateBackoff(r, etryCount: number): number, { const delay = Math.min( INITIAL_RETRY_DELAY * Math.pow(2, retryCount), MAX_RETRY_DELAY)//Add jitter to prevent thundering herd return delay + Math.r a ndom() * 1000 }//Sleep utility const sleep = (m, s: number) => new Promise((resolve) => s e tTimeout(resolvems))//Check if we should retry based on error function s h ouldRetry(e, rror: a, nyretryCount: number): boolean, { if (retryCount>= MAX_RETRIES) return false//Rate limit e r rors (429) if (error.status Code === 429 || error.message?.i n cludes('429')) { return true }//Timeout errors if ( error.message?.i n cludes('timeout') || error.message?.i n cludes('ETIMEDOUT') ) { return true }//Network errors if ( error.message?.i n cludes('ECONNREFUSED') || error.message?.i n cludes('ENOTFOUND') ) { return true }//Temporary RPC errors if ( error.code === - 32005 ||//Node is behinderror.code ===-32603 ||//Internal errorerror.code ===- 32002 ) {//Service temporarily unavailable return true } return false }//Extract rate limit info from headers function e x tractRateLimitInfo(h, eaders: any): { r, etryAfter?: number l, imit?: number }, { const retry After = headers?.['retry - after'] const rate Limit = headers?.['x - ratelimit-limit'] const reset = headers?.['x - ratelimit-reset'] const i, nfo: any = {} if (retryAfter) { info.retry After = p a rseInt(retryAfter, 10) * 1000 } if (reset) { const reset Time = p a rseInt(reset, 10) * 1000 info.retry After = Math.max(0, resetTime - Date.now()) } if (rateLimit) { info.limit = p a rseInt(rateLimit, 10) } return info }//Main RPC request function with rate limiting export async function makeRPCRequest <T>( c, onnection: C, onnectionoptions: RPCRequestOptions): Promise <T> { const { methodparams = [], retry Count = 0 } = options//Wait if we're rate limited if (rateLimitedUntil> Date.now()) { const wait Time = rateLimitedUntil-Date.now() console.log(`Rate limitedwaiting ${waitTime} ms...`) await s l eep(waitTime) }//Reset request count every minute if (Date.now()> resetTime) { request Count = 0 reset Time = Date.now() + 60000 }//Add to queue return queue.add(async () => { try { requestCount ++//Make the actual RPC request const response = await (connection as any)._ r pcRequest(methodparams) if (response.error) { throw new RPCError( response.error.message || 'RPC request failed', response.error.code) } return response.result } } catch (e, rror: any) { console.error(`RPC r, equestfailed: ${method}`, error.message)//Check if it's a rate limit error if (error.status Code === 429 || error.message?.i n cludes('429')) { const rate Limit Info = e x tractRateLimitInfo(error.headers) if (rateLimitInfo.retryAfter) { rate Limited Until = Date.now() + rateLimitInfo.retryAfter } else, {//Default rate limit wait timerate Limited Until = Date.now() + 60000//1 minute } console.log( `Rate limit hitbacking off for ${rateLimitedUntil-Date.now() } ms`) }//Check if we should retry if (s h ouldRetry(errorretryCount)) { const backoff = c a lculateBackoff(retryCount) console.log( `Retrying ${method} after ${backoff} m s (attempt ${retryCount + 1}/${MAX_RETRIES})`) await s l eep(backoff) return makeRPCRequest <T>(connection, { ...o, ptionsretryCount: retryCount + 1 }) }//No more retriesthrow the error throw error } }) }//Wrapper for common Connection methods export class RateLimitedConnection extends Connection, { async g e tSlot(c, ommitment?: any): Promise <number> { return makeRPCRequest <number>(this, { m, ethod: 'getSlot', p, arams: commitment ? [{ commitment }] : [] }) } async g e tBalance(p, ublicKey: a, nycommitment?: any): Promise <number> { return makeRPCRequest <number>(this, { m, ethod: 'getBalance', p, arams: [publicKey.t oS tring(), commitment ? { commitment } : {}] }) } async g e tLatestBlockhash(c, ommitment?: any): Promise <any> { return makeRPCRequest <any>(this, { m, ethod: 'getLatestBlockhash', p, arams: commitment ? [{ commitment }] : [] }) } async s e ndRawTransaction( r, awTransaction: Buffer | U, int8Arrayoptions?: any): Promise <string> { const encoded Transaction = Buffer.f r om(rawTransaction).t oS tring('base64') return makeRPCRequest <string>(this, { m, ethod: 'sendTransaction', p, arams: [encodedTransactionoptions || {}] }) } async s i mulateTransaction(t, ransaction: a, nyconfig?: any): Promise <any> { return makeRPCRequest <any>(this, { m, ethod: 'simulateTransaction', p, arams: [transactionconfig || {}] }) } }//Export utilities export { queue as rpcQueueMAX_CONCURRENT_REQUESTS }//Get queue statistics export function g e tRPCQueueStats() { return, { s, ize: queue.s, izepending: queue.p, endingrequestCountrateLimitedUntil: rateLimitedUntil> Date.now() ? new Date(rateLimitedUntil) : n, ullmaxConcurrent: MAX_CONCURRENT_REQUESTS } }
