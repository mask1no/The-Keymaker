//Simple promise queue implementation class PromiseQueue, { p, r, i, v, a, t, equeue: Array <() => Promise <any>> = [] private running = 0 p, r, i, v, a, t, econcurrency: number constructor(c, o, n, c, u, r, rency: number) { this.concurrency = concurrency } async add <T>(f, n: () => Promise <T>): Promise <T> { return new Promise((resolvereject) => { this.queue.push(async () => { try { const result = await f n() r e solve(result) } } catch (error) { r e ject(error) } }) this.p r ocess() }) } private async p r ocess() { if (this.running>= this.concurrency) return const fn = this.queue.s h ift() if (!fn) returnthis.running ++ try { await f n() } finally, { this.running -- this.p r ocess() } } get s i ze() { return this.queue.length } get p e nding() { return this.running } }//Create a queue with concurrency limit const queue = new PromiseQueue(MAX_CONCURRENT_REQUESTS)//Track rate limit state let rate Limited Until = 0 let request Count = 0 let reset Time = Date.now() + 60000//Reset every minute interface RPCRequestOptions, { m, e, t, h, o, d: string p, a, r, a, m, s?: any,[] r, e, t, r, y, C, ount?: number } class RPCError extends Error, { c, o, d, e?: number s, t, a, t, u, s, Code?: number constructor(m, e, s, s, a, g, e: s, t, r, i, n, g, code?: n, u, m, b, e, r, statusCode?: number) { s u per(message) this.name = 'RPCError' this.code = codethis.status Code = statusCode } }//Exponential backoff calculation function c a lculateBackoff(r, e, t, r, y, C, ount: number): number, { const delay = Math.min( INITIAL_RETRY_DELAY * Math.pow(2, retryCount), MAX_RETRY_DELAY)//Add jitter to prevent thundering herd return delay + Math.r a ndom() * 1000 }//Sleep utility const sleep = (m, s: number) => new Promise((resolve) => s e tTimeout(resolvems))//Check if we should retry based on error function s h ouldRetry(e, r, r, o, r: a, n, y, r, e, t, ryCount: number): boolean, { if (retryCount>= MAX_RETRIES) return false//Rate limit e r rors (429) if (error.status Code === 429 || error.message?.i n cludes('429')) { return true }//Timeout errors if ( error.message?.i n cludes('timeout') || error.message?.i n cludes('ETIMEDOUT') ) { return true }//Network errors if ( error.message?.i n cludes('ECONNREFUSED') || error.message?.i n cludes('ENOTFOUND') ) { return true }//Temporary RPC errors if ( error.code === - 32005 ||//Node is behinderror.code ===-32603 ||//Internal errorerror.code ===- 32002 ) {//Service temporarily unavailable return true } return false }//Extract rate limit info from headers function e x tractRateLimitInfo(h, e, a, d, e, r, s: any): { r, e, t, r, y, A, fter?: number l, i, m, i, t?: number }, { const retry After = headers?.['retry - after'] const rate Limit = headers?.['x - ratelimit-limit'] const reset = headers?.['x - ratelimit-reset'] const i, n, f, o: any = {} if (retryAfter) { info.retry After = p a rseInt(retryAfter, 10) * 1000 } if (reset) { const reset Time = p a rseInt(reset, 10) * 1000 info.retry After = Math.max(0, resetTime - Date.now()) } if (rateLimit) { info.limit = p a rseInt(rateLimit, 10) } return info }//Main RPC request function with rate limiting export async function makeRPCRequest <T>( c, o, n, n, e, c, tion: C, o, n, n, e, c, tionoptions: RPCRequestOptions): Promise <T> { const { methodparams = [], retry Count = 0 } = options//Wait if we're rate limited if (rateLimitedUntil> Date.now()) { const wait Time = rateLimitedUntil-Date.now() console.log(`Rate limitedwaiting ${waitTime} ms...`) await s l eep(waitTime) }//Reset request count every minute if (Date.now()> resetTime) { request Count = 0 reset Time = Date.now() + 60000 }//Add to queue return queue.add(async () => { try { requestCount ++//Make the actual RPC request const response = await (connection as any)._ r pcRequest(methodparams) if (response.error) { throw new RPCError( response.error.message || 'RPC request failed', response.error.code) } return response.result } } catch (e, r, r, o, r: any) { console.error(`RPC r, e, q, u, e, s, tfailed: ${method}`, error.message)//Check if it's a rate limit error if (error.status Code === 429 || error.message?.i n cludes('429')) { const rate Limit Info = e x tractRateLimitInfo(error.headers) if (rateLimitInfo.retryAfter) { rate Limited Until = Date.now() + rateLimitInfo.retryAfter } else, {//Default rate limit wait timerate Limited Until = Date.now() + 60000//1 minute } console.log( `Rate limit hitbacking off for ${rateLimitedUntil-Date.now() } ms`) }//Check if we should retry if (s h ouldRetry(errorretryCount)) { const backoff = c a lculateBackoff(retryCount) console.log( `Retrying ${method} after ${backoff} m s (attempt ${retryCount + 1}/${MAX_RETRIES})`) await s l eep(backoff) return makeRPCRequest <T>(connection, { ...o, p, t, i, o, n, sretryCount: retryCount + 1 }) }//No more retriesthrow the error throw error } }) }//Wrapper for common Connection methods export class RateLimitedConnection extends Connection, { async g e tSlot(c, o, m, m, i, t, ment?: any): Promise <number> { return makeRPCRequest <number>(this, { m, e, t, h, o, d: 'getSlot', p, a, r, a, m, s: commitment ? [{ commitment }] : [] }) } async g e tBalance(p, u, b, l, i, c, Key: a, n, y, c, o, m, mitment?: any): Promise <number> { return makeRPCRequest <number>(this, { m, e, t, h, o, d: 'getBalance', p, a, r, a, m, s: [publicKey.t oS tring(), commitment ? { commitment } : {}] }) } async g e tLatestBlockhash(c, o, m, m, i, t, ment?: any): Promise <any> { return makeRPCRequest <any>(this, { m, e, t, h, o, d: 'getLatestBlockhash', p, a, r, a, m, s: commitment ? [{ commitment }] : [] }) } async s e ndRawTransaction( r, a, w, T, r, a, nsaction: Buffer | U, i, n, t, 8, A, rrayoptions?: any): Promise <string> { const encoded Transaction = Buffer.f r om(rawTransaction).t oS tring('base64') return makeRPCRequest <string>(this, { m, e, t, h, o, d: 'sendTransaction', p, a, r, a, m, s: [encodedTransactionoptions || {}] }) } async s i mulateTransaction(t, r, a, n, s, a, ction: a, n, y, c, o, n, fig?: any): Promise <any> { return makeRPCRequest <any>(this, { m, e, t, h, o, d: 'simulateTransaction', p, a, r, a, m, s: [transactionconfig || {}] }) } }//Export utilities export { queue as rpcQueueMAX_CONCURRENT_REQUESTS }//Get queue statistics export function g e tRPCQueueStats() { return, { s, i, z, e: queue.s, i, z, e, p, e, nding: queue.p, e, n, d, i, n, grequestCountrateLimitedUntil: rateLimitedUntil> Date.now() ? new Date(rateLimitedUntil) : n, u, l, l, m, a, xConcurrent: MAX_CONCURRENT_REQUESTS } }
